#!/usr/bin/env python3
"""
Test if the API can load configuration from .env file correctly.
"""
import sys
import os
sys.path.append('/root/projects/test_task')

def test_config_loading():
    """Test configuration loading."""
    print("ğŸ§ª Testing Configuration Loading")
    print("=" * 40)
    
    try:
        from backend.config import config
        
        print("âœ… Configuration loaded successfully!")
        print(f"ğŸ“Š LLM Provider: {config.llm.default_provider}")
        print(f"ğŸ¤– LLM Model: {config.llm.default_model}")
        print(f"ğŸŒ¡ï¸ Temperature: {config.llm.default_temperature}")
        print(f"ğŸ”‘ OpenAI API Key: {'***' if config.llm.openai_api_key else 'Not set'}")
        print(f"ğŸŒ API Port: {config.api.port}")
        
        # Test if configuration is valid for OpenAI
        if config.llm.default_provider.lower() == "openai":
            if config.llm.openai_api_key:
                print("âœ… OpenAI configuration is complete!")
            else:
                print("âŒ OpenAI provider selected but no API key found!")
                return False
        
        return True
        
    except Exception as e:
        print(f"âŒ Configuration loading failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_api_initialization():
    """Test if the API can initialize with the configuration."""
    print("\nğŸš€ Testing API Initialization")
    print("=" * 40)
    
    try:
        from backend.rag.pipeline import RAGPipeline, ModelProvider
        from backend.config import config
        
        # Test creating RAG pipeline with config
        provider = ModelProvider.OLLAMA if config.llm.default_provider.lower() == "ollama" else ModelProvider.OPENAI
        
        print(f"ğŸ”§ Creating RAG pipeline with {provider.value}...")
        
        pipeline = RAGPipeline(
            provider=provider,
            model_name=config.llm.default_model,
            temperature=config.llm.default_temperature,
            openai_api_key=config.llm.openai_api_key
        )
        
        print("âœ… RAG pipeline created successfully!")
        print(f"ğŸ“‹ Provider: {pipeline.provider.value}")
        print(f"ğŸ“‹ Model: {pipeline.model_name}")
        print(f"ğŸ“‹ Temperature: {pipeline.temperature}")
        
        return True
        
    except Exception as e:
        print(f"âŒ API initialization failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Main test function."""
    config_ok = test_config_loading()
    
    if config_ok:
        api_ok = test_api_initialization()
        
        if api_ok:
            print("\nğŸ‰ Everything looks good!")
            print("ğŸ’¡ Your .env configuration will be used automatically.")
            print("ğŸ’¡ You don't need to configure via UI unless you want to change settings.")
            return 0
        else:
            print("\nğŸ’¥ API initialization failed!")
            return 1
    else:
        print("\nğŸ’¥ Configuration loading failed!")
        return 1

if __name__ == "__main__":
    sys.exit(main())
